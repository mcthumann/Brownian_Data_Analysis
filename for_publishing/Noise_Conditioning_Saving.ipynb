{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "8b9bdd998b703a1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:22:31.353036Z",
     "start_time": "2025-06-30T20:22:27.116304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n"
   ],
   "id": "441f2aa9fd11149f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:22:31.778043Z",
     "start_time": "2025-06-30T20:22:31.369788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SHARED\n",
    "_k_b = scipy.constants.k\n",
    "_rho = 4200\n",
    "_rho_f = 790\n",
    "\n",
    "_r =  1.3684204359439797e-06\n",
    "_gain = np.sqrt(537680100419411.0)\n",
    "_K = 8.046462556775461e-05\n",
    "\n",
    "_m = 4/3 *np.pi *_r**3*_rho + 2/3 *np.pi *_r**3*_rho_f\n",
    "_temp = 293\n",
    "_viscous = 0.32e-3\n",
    "_v_force = 6*np.pi*_r*_viscous\n",
    "\n",
    "bin_number_data = 30\n",
    "timestep_data = bin_number_data/200000000\n",
    "\n",
    "print(timestep_data)\n",
    "print(\"momentum relation time is \" + str(_m/_v_force))\n"
   ],
   "id": "4327fd68d6c63efd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5e-07\n",
      "momentum relation time is 5.3099070775713524e-06\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:22:32.076011Z",
     "start_time": "2025-06-30T20:22:32.072600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the average MSD\n",
    "def compute_msd(time_trace, dt):\n",
    "    n = len(time_trace)\n",
    "    msd = np.zeros(n)  # Allocate array for MSD\n",
    "    lag_times = np.arange(n) * dt  # Calculate lag times\n",
    "\n",
    "    for tau in tqdm(range(n)):\n",
    "        displacements = time_trace[tau:] - time_trace[:n - tau]\n",
    "        msd[tau] = np.mean(displacements**2)\n",
    "\n",
    "    return msd, lag_times\n",
    "\n",
    "# Calculate the zero init MSD\n",
    "\n",
    "def compute_init_msd(sequence):\n",
    "    MS = np.zeros(len(sequence))\n",
    "    for i in range(1, len(MS)):\n",
    "        MS[i] = (sequence[0] - sequence[i])**2\n",
    "        #print(np.abs(sequence[0] - sequence[1]) / np.abs(sequence[50] - sequence[55]))\n",
    "    return MS\n",
    "\n",
    "def compute_init_msd2(time_trace, dt):\n",
    "\n",
    "    n = len(time_trace)\n",
    "    lag_times = np.arange(n) * dt  # Calculate lag times\n",
    "\n",
    "    msd_ = [(time_trace[k]-time_trace[0])**2 for k in range(n)]\n",
    "    return msd_, lag_times\n"
   ],
   "id": "48344925a2de7b07",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T20:22:32.089660Z",
     "start_time": "2025-06-30T20:22:32.084569Z"
    }
   },
   "source": [
    "# ANALYTICAL FUNCTIONS\n",
    "\n",
    "# GENERAL WHITE NOISE\n",
    "def msd_wn(t):\n",
    "    tau = _m / _v_force\n",
    "    omega_0 = np.sqrt(_K / _m)\n",
    "    omega_1 = np.sqrt(1/(4*tau**2) - omega_0**2)\n",
    "    return (2*_k_b*_temp/_K)*(1-np.exp(-t/(2*tau))*(np.cosh(omega_1*t)+(1/(2*omega_1*tau))*np.sinh(omega_1*t)))\n",
    "\n",
    "# INITIALLY ZERO WHITE NOISE\n",
    "def just_noise(t):\n",
    "\n",
    "    tau = _m / _v_force\n",
    "    omega_0 = np.sqrt(_K / _m)\n",
    "    omega_1 = np.sqrt(1/(4*tau**2) - omega_0**2)\n",
    "    numerator = tau*np.exp(-1*t / tau)*(-1-4*tau**2*(-1 + np.exp(t/tau))*omega_1**2 + np.cosh(2*t*omega_1)+2*tau*omega_1*np.sinh(2*t*omega_1))\n",
    "    denominator = -2 + 8*tau**2*omega_1**2#-1*8*tau**2*omega_0**2\n",
    "    final_scale = 12*np.pi*_r*_viscous*_k_b*_temp / _m**2 / omega_1**2\n",
    "    return (numerator / denominator) * final_scale\n",
    "\n",
    "# INITIAL SET VARIANCE WHITE NOISE\n",
    "def known_initial_v_0(t, tol_percent):\n",
    "\n",
    "    tau = _m / _v_force\n",
    "\n",
    "    #Defines important auxillary variables\n",
    "\n",
    "    omega_0 = np.sqrt(_K / _m)\n",
    "    omega_1 = np.sqrt(1/(4*tau**2) - omega_0**2)\n",
    "    T = omega_1*t\n",
    "\n",
    "    #Gets contribution from the thermal white noise\n",
    "    gamma = just_noise(t)\n",
    "\n",
    "    #Gets contribution from initial position variation\n",
    "    # hyp_factors = np.exp(-1*t/tau)*(np.cosh(T)**2 + 1/(4*(omega_1*tau)**2)*np.sinh(T)**2 + 1/(omega_1*tau)*np.cosh(T)*np.sinh(T)) - np.exp(-1*t/(2*tau))*(2*np.cosh(T) - 1/(2*omega_1*tau)*np.sinh(T))\n",
    "    hyp_factors = (1 - np.exp(-t/(2*tau))*(np.cosh(omega_1*t) + np.sinh(omega_1*t)/(2*omega_1*tau)))**2\n",
    "\n",
    "    #alpha easier to type than tol_percent\n",
    "    alpha = tol_percent\n",
    "\n",
    "    #Gets the second moment of the velocity assuming a probabiity distribution of\n",
    "    #a Gaussian cut off on its wings by some fraction of its standard deviation (alpha/tol_percent)\n",
    "    updated_sigma = 1 - alpha*np.exp(-alpha**2/2)*np.sqrt(2/np.pi)/scipy.special.erf(alpha/np.sqrt(2))\n",
    "\n",
    "    #Calculates the contribution from the intitial velocity spread\n",
    "    velo = np.exp(-1*t/tau) / omega_1**2 * np.sinh(omega_1*t)**2 *_k_b*_temp / _m * updated_sigma\n",
    "\n",
    "    #Puts the pieces together\n",
    "    return _k_b*_temp / _K * ( hyp_factors) + gamma + velo\n",
    "\n",
    "# HYDRODYNAMIC GENERAL CASE\n",
    "def hydro_msd(t):\n",
    "    trap_const = _K\n",
    "    use_mass = _m\n",
    "    m_f = 2 / 3 * np.pi * _r ** 3 * 1000\n",
    "    t_k = (6 * np.pi * _r * _viscous) / _K\n",
    "    t_f = (_rho_f * _r ** 2) / _viscous\n",
    "    t_p = _m / (6 * np.pi * _r * _viscous)\n",
    "    print(\"tp is \" + str(t_p))\n",
    "    print(t_f)\n",
    "    # find roots\n",
    "    # a * z^4 + b * z^3 + c * z^2 + d * z + e = 0\n",
    "    a_ = t_p\n",
    "    b = -1 * np.sqrt(t_f)\n",
    "    c = 1\n",
    "    d = 0\n",
    "    e = 1 / t_k\n",
    "\n",
    "    # Coefficients array for the polynomial equation\n",
    "    coefficients = [a_, b, c, d, e]\n",
    "\n",
    "    # Find the roots\n",
    "    roots = np.roots(coefficients)\n",
    "\n",
    "    # I need to learn how to vectorize my code better\n",
    "    term_1 = scipy.special.erfcx(roots[0] * np.sqrt(t)) / (\n",
    "                roots[0] * (roots[0] - roots[1]) * (roots[0] - roots[2]) * (roots[0] - roots[3]))\n",
    "    term_2 = scipy.special.erfcx(roots[1] * np.sqrt(t)) / (\n",
    "                roots[1] * (roots[1] - roots[0]) * (roots[1] - roots[2]) * (roots[1] - roots[3]))\n",
    "    term_3 = scipy.special.erfcx(roots[2] * np.sqrt(t)) / (\n",
    "                roots[2] * (roots[2] - roots[1]) * (roots[2] - roots[0]) * (roots[2] - roots[3]))\n",
    "    term_4 = scipy.special.erfcx(roots[3] * np.sqrt(t)) / (\n",
    "                roots[3] * (roots[3] - roots[1]) * (roots[3] - roots[2]) * (roots[3] - roots[0]))\n",
    "\n",
    "    D = _k_b * _temp / (6 * np.pi * _viscous * _r)\n",
    "    # Returns theoretical MSD\n",
    "    return np.real(2 * _k_b * _temp / trap_const + 2 * _k_b * _temp / (use_mass) * (\n",
    "                term_1 + term_2 + term_3 + term_4))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:51:11.378380Z",
     "start_time": "2025-06-30T20:22:32.201682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATA\n",
    "\n",
    "chunksize = 10 ** 6  # Adjust chunk size based on your memory availability\n",
    "chunks1 = []\n",
    "\n",
    "for chunk in pd.read_csv(rf'C:\\Users\\mct2723\\Desktop\\Repos\\Brownian_Data_Analysis\\for_publishing\\data\\noise_position_bin{bin_number_data}.csv', chunksize=chunksize, low_memory=False):\n",
    "    # process each chunk individually or filter/aggregate it\n",
    "    chunks1.append(chunk)\n",
    "\n",
    "data_df_pos_data = pd.concat(chunks1, ignore_index=True)\n",
    "\n",
    "chunks2 = []\n",
    "\n",
    "for chunk in pd.read_csv(rf'C:\\Users\\mct2723\\Desktop\\Repos\\Brownian_Data_Analysis\\for_publishing\\data\\noise_velocity_bin{bin_number_data}.csv', chunksize=chunksize, low_memory=False):\n",
    "    # process each chunk individually or filter/aggregate it\n",
    "    chunks2.append(chunk)\n",
    "\n",
    "data_df_vel_data = pd.concat(chunks2, ignore_index=True)\n",
    "\n",
    "# Convert DataFrame into a numpy array where each column is an entry\n",
    "traces_data = data_df_pos_data.to_numpy().T  # transpose if you want each col as an entry\n",
    "\n",
    "# Convert DataFrame into a numpy array where each column is an entry\n",
    "v_traces_data = data_df_vel_data.to_numpy().T  # transpose if you want each col as an entry\n",
    "\n",
    "\n",
    "# GET THE EQ MSD\n",
    "all_msd_data = []\n",
    "lag_times_data = 0\n",
    "for series in traces_data:\n",
    "    msd, lag_times_data = compute_msd(series, timestep_data)\n",
    "    all_msd_data.append(msd)\n",
    "\n",
    "eq_msd_data = np.mean(all_msd_data, axis=0)\n"
   ],
   "id": "caa226dac07d2f77",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559240/559240 [05:41<00:00, 1638.47it/s] \n",
      "100%|██████████| 559240/559240 [05:27<00:00, 1708.93it/s] \n",
      "100%|██████████| 559240/559240 [05:28<00:00, 1702.40it/s] \n",
      "100%|██████████| 559240/559240 [05:36<00:00, 1661.51it/s] \n",
      "100%|██████████| 559240/559240 [06:24<00:00, 1453.15it/s] \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:51:11.834682Z",
     "start_time": "2025-06-30T20:51:11.463955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Error bar calculation\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "import numpy as np\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "def estimate_corrected_error2(data):\n",
    "    x = np.array(data, dtype=np.float64)\n",
    "\n",
    "    # Normalize to avoid floating point underflow\n",
    "    scale = np.max(np.abs(x))\n",
    "    if scale == 0:\n",
    "        return {\n",
    "            \"mean\": 0.0,\n",
    "            \"std_dev\": 0.0,\n",
    "            \"correlation_factor_f\": 0.0,\n",
    "            \"corrected_error_bar\": 0.0\n",
    "        }\n",
    "    x_scaled = x / scale\n",
    "\n",
    "    N = len(x_scaled)\n",
    "    mean = np.mean(x_scaled)\n",
    "    s2 = np.var(x_scaled, ddof=1)\n",
    "    if s2 == 0:\n",
    "        return {\n",
    "            \"mean\": mean * scale,\n",
    "            \"std_dev\": 0.0,\n",
    "            \"correlation_factor_f\": 0.0,\n",
    "            \"corrected_error_bar\": 0.0\n",
    "        }\n",
    "\n",
    "    s = np.sqrt(s2)\n",
    "    x_centered = x_scaled - mean\n",
    "    numerator = np.sum(x_centered ** 2)\n",
    "    sum_xc = np.sum(x_centered)\n",
    "\n",
    "    def chi_squared(f):\n",
    "        if not (0 < f < 1):\n",
    "            return np.inf\n",
    "\n",
    "        try:\n",
    "            denominator = 1 - f\n",
    "            correction = f / (1 + f * (N - 1))\n",
    "            total = (numerator / s2 - correction * (sum_xc ** 2) / s2) / denominator\n",
    "            if not np.isfinite(total):\n",
    "                return np.inf\n",
    "            return total - (N - 1)\n",
    "        except Exception:\n",
    "            return np.inf\n",
    "\n",
    "    # Try to solve for f, with fallback if it fails\n",
    "    try:\n",
    "        f_opt = brentq(chi_squared, 1e-4, 0.999)\n",
    "    except ValueError:\n",
    "        f_opt = 0.0  # fallback: assume no correlation\n",
    "\n",
    "    sigma_corrected = s * np.sqrt((1 + f_opt * (N - 1)) / N)\n",
    "\n",
    "    # Rescale outputs\n",
    "    return {\n",
    "        \"mean\": mean * scale,\n",
    "        \"std_dev\": s * scale,\n",
    "        \"correlation_factor_f\": f_opt,\n",
    "        \"corrected_error_bar\": sigma_corrected * scale\n",
    "    }\n",
    "\n",
    "def estimate_corrected_error(data):\n",
    "\n",
    "    x = np.array(data)\n",
    "    N = len(x)\n",
    "    mean = np.mean(x)\n",
    "    s2 = np.var(x, ddof=1)\n",
    "    s = np.sqrt(s2)\n",
    "    x_centered = x - mean\n",
    "\n",
    "    # Function to solve: Schmelling's chi^2(f) = N - 1\n",
    "    def chi_squared(f):\n",
    "        numerator = np.sum(x_centered ** 2)\n",
    "        denominator = 1 - f\n",
    "        correction = f / (1 + f * (N - 1))\n",
    "        total = (numerator / s2 - correction * (np.sum(x_centered) ** 2) / s2) / denominator\n",
    "        return total - (N - 1)\n",
    "\n",
    "    # Solve for f in a safe range [0, 0.999] to avoid singular matrix\n",
    "    f_opt = brentq(chi_squared, 1e-2, 0.999)\n",
    "\n",
    "    # Corrected standard error of the mean\n",
    "    sigma_corrected = s * np.sqrt((1 + f_opt * (N - 1)) / N)\n",
    "\n",
    "    return {\n",
    "        \"mean\": mean,\n",
    "        \"std_dev\": s,\n",
    "        \"correlation_factor_f\": f_opt,\n",
    "        \"corrected_error_bar\": sigma_corrected\n",
    "    }\n"
   ],
   "id": "6dd20652b82c0a6c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T20:51:11.912429Z",
     "start_time": "2025-06-30T20:51:11.852431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from scipy import constants\n",
    "\n",
    "def compute_roots(m, K, r, eta, rho_f):\n",
    "    t_f = (rho_f * r ** 2) / eta\n",
    "    t_p = m / (6 * np.pi * r * eta)\n",
    "    a = 1\n",
    "    b = -6*math.pi*r**2*np.sqrt(rho_f*eta)/m\n",
    "    c = 6*math.pi*r*eta/m\n",
    "    d = 0\n",
    "    e = K/m\n",
    "\n",
    "    coeffs = [a, b, c, d, e]\n",
    "    return np.roots(coeffs)\n",
    "\n",
    "roots = compute_roots(_m, _K, _r, _viscous, _rho_f)\n",
    "\n",
    "def a_inverse_form(t, roots):\n",
    "    return np.real((1/_m) * sum(\n",
    "        (z**3 * scipy.special.erfcx(z * np.sqrt(t))) /\n",
    "        (np.prod([z - z_j for z_j in roots if z != z_j])) for z in roots))\n",
    "\n",
    "def b_inverse_form(t, roots):\n",
    "    return np.real((1/_m) * sum(\n",
    "        (z * scipy.special.erfcx(z * np.sqrt(t))) /\n",
    "        (np.prod([z - z_j for z_j in roots if z != z_j])) for z in roots))\n",
    "\n",
    "def c_inverse_form(t, roots):\n",
    "    a = roots[0]\n",
    "    b = roots[1]\n",
    "    c = roots[2]\n",
    "    d = roots[3]\n",
    "\n",
    "    m_over_k = 1/(a*b*c*d)\n",
    "\n",
    "    ret = np.real((1/_m) * sum(\n",
    "        (scipy.special.erfcx(z * np.sqrt(t))) /\n",
    "        (z*(np.prod([z - z_j for z_j in roots if z != z_j]))) for z in roots))\n",
    "\n",
    "    return ret + m_over_k/_m\n",
    "\n",
    "def s_half_b_inverse_form(t, roots):\n",
    "    return np.real((-1/_m) * sum(\n",
    "        (z**2 * scipy.special.erfcx(z * np.sqrt(t))) /\n",
    "        (np.prod([z - z_j for z_j in roots if z != z_j])) for z in roots))\n",
    "\n",
    "def s_minus_half_b_inverse_form(t, roots):\n",
    "     return np.real((-1/_m) * sum(\n",
    "        (scipy.special.erfcx(z * np.sqrt(t))) /\n",
    "        (np.prod([z - z_j for z_j in roots if z != z_j])) for z in roots))\n",
    "\n",
    "def experfc_inverse_form(t, tau, roots):\n",
    "    return np.real((1/_m) * sum(\n",
    "        (z * ((1/np.sqrt(np.pi*(t-tau)))-(z*np.exp(z**2*(t-tau))*scipy.special.erfc(z*np.sqrt(t-tau))))) /\n",
    "        (np.prod([z - z_j for z_j in roots if z != z_j])) for z in roots))\n",
    "\n",
    "def ensemble_r_term(t1, t2, m, K, roots):\n",
    "    return np.real((constants.k*_temp)*(c_inverse_form(t1, roots) + c_inverse_form(t2, roots) - c_inverse_form(np.abs(t2-t1), roots) - m*b_inverse_form(t1, roots)*b_inverse_form(t2, roots) - K*c_inverse_form(t1, roots)*c_inverse_form(t2, roots)))\n",
    "\n",
    "def e_and_f(t, mass, radius, rho_f, eta, x0, v0, roots):\n",
    "    gamma = 6*np.pi*radius*eta\n",
    "    z = 6*radius**2*np.pi*np.sqrt(rho_f*eta)\n",
    "    return mass*x0*a_inverse_form(t, roots) + mass*v0*b_inverse_form(t, roots) + gamma*x0*b_inverse_form(t, roots) + z*x0*s_half_b_inverse_form(t, roots) #+ z*v0*s_minus_half_b_inverse_form(t, roots)\n",
    "\n",
    "def x_t1_x_t2(t1, t2, m, K, radius, eta, rho_f, x0, v0):\n",
    "    return e_and_f(t1, m, radius, rho_f, eta, x0, v0, roots)*e_and_f(t2, m, radius, rho_f, eta, x0, v0, roots) + ensemble_r_term(t1,t2, m, K, roots)\n",
    "\n",
    "def full_hydro_msd(t1, t2, m, K, radius, eta, rho_f, x0, v0):\n",
    "    return x_t1_x_t2(t1, t1, m, K, radius, eta, rho_f, x0, v0) + x_t1_x_t2(t2, t2, m, K, radius, eta, rho_f, x0, v0) - 2 * x_t1_x_t2(t1, t2, m, K, radius, eta, rho_f, x0, v0)\n",
    "#\n",
    "def stat_hydro_msd(t, roots):\n",
    "    return 2*constants.k*_temp*c_inverse_form(t, roots)\n",
    "\n",
    "def v_t1_v_t2(t1, t2, m, K):\n",
    "    return _k_b*_temp*(a_inverse_form(np.abs(t2-t1), roots) - m*a_inverse_form(t1, roots)*a_inverse_form(t2, roots) - K*b_inverse_form(t1, roots)*b_inverse_form(t2, roots))\n",
    "\n"
   ],
   "id": "75a7da99a6f1df00",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:05:33.924989Z",
     "start_time": "2025-06-30T21:01:31.112041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LOOK FOR SPECIFIC SPEEDS\n",
    "\n",
    "speeds = [0, .5, 1, 2]\n",
    "traces_per_speed = [0, 0, 0, 0]\n",
    "\n",
    "data_speeds_msds = []\n",
    "error_bar_speeds= []\n",
    "\n",
    "speed_tol = [.001, .005, .01, .01]\n",
    "lag_times_speed_data = 0\n",
    "\n",
    "for s in range(len(speeds)):\n",
    "\n",
    "    all_speeds_msd_data = []\n",
    "\n",
    "    init_len_data = int(len(traces_data[0])/10)\n",
    "\n",
    "    for i in range(len(traces_data)):\n",
    "        speed_idxs_data = []\n",
    "        print(\"std of data vel \" + str(np.std(v_traces_data[i])))\n",
    "        print(\"kb*T*gain = \" + str(_gain*np.sqrt(_k_b*_temp/_m)))\n",
    "\n",
    "        v_tolerance = (speeds[s] * 6525)\n",
    "        speed_tolerance = speed_tol[s] * 6525\n",
    "        v_indices_data = np.where((v_traces_data[i] < v_tolerance + speed_tolerance) & (v_traces_data[i] > v_tolerance - speed_tolerance))[0]\n",
    "\n",
    "        for idx in v_indices_data:\n",
    "            if idx + init_len_data < len(traces_data[i]):\n",
    "                speed_idxs_data.append(idx)\n",
    "\n",
    "        print(\"total idx data: \" + str(len(speed_idxs_data)))\n",
    "        traces_per_speed[s] += len(speed_idxs_data)\n",
    "        for idx in speed_idxs_data:\n",
    "            msd, lag_times_speed_data = compute_init_msd2(traces_data[i][idx:idx+init_len_data], timestep_data)\n",
    "            all_speeds_msd_data.append(msd)\n",
    "\n",
    "    print(f\"-------TOTAL TRACES DATA {traces_per_speed[s]}------------\")\n",
    "\n",
    "    # Calculate error bar for each lag time at this speed\n",
    "    # print(f\"SHAPE {np.array(all_speeds_msd_data).shape}\")\n",
    "    all_speeds_msd_data_array = np.array(all_speeds_msd_data)\n",
    "\n",
    "    all_lag_data_groups = all_speeds_msd_data_array.T\n",
    "\n",
    "    speed_msd_data = np.mean(all_speeds_msd_data_array, axis=0)\n",
    "\n",
    "    data_speeds_msds.append(speed_msd_data)\n",
    "\n"
   ],
   "id": "a8084f7f699fde27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std of data vel 2633.446998595911\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 1029\n",
      "std of data vel 2858.3258512076545\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 924\n",
      "std of data vel 2286.195201013436\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 1172\n",
      "std of data vel 2453.0065680872476\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 1073\n",
      "std of data vel 2360.6077390900186\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 1066\n",
      "-------TOTAL TRACES DATA 5264------------\n",
      "std of data vel 2633.446998595911\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 2218\n",
      "std of data vel 2858.3258512076545\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 2333\n",
      "std of data vel 2286.195201013436\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 1912\n",
      "std of data vel 2453.0065680872476\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 2041\n",
      "std of data vel 2360.6077390900186\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 2155\n",
      "-------TOTAL TRACES DATA 10659------------\n",
      "std of data vel 2633.446998595911\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 396\n",
      "std of data vel 2858.3258512076545\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 726\n",
      "std of data vel 2286.195201013436\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 188\n",
      "std of data vel 2453.0065680872476\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 339\n",
      "std of data vel 2360.6077390900186\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 284\n",
      "-------TOTAL TRACES DATA 1933------------\n",
      "std of data vel 2633.446998595911\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 0\n",
      "std of data vel 2858.3258512076545\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 2\n",
      "std of data vel 2286.195201013436\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 0\n",
      "std of data vel 2453.0065680872476\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 0\n",
      "std of data vel 2360.6077390900186\n",
      "kb*T*gain = 6641.283924201093\n",
      "total idx data: 0\n",
      "-------TOTAL TRACES DATA 2------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T21:06:01.823517Z",
     "start_time": "2025-06-30T21:05:46.103764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "times_analytic = np.logspace(np.log10(lag_times_data[1]), np.log10(lag_times_data[-1]), 200)\n",
    "\n",
    "mu = 0\n",
    "# sigma_v = np.sqrt(_k_b*_temp/_m)\n",
    "sigma_x = np.sqrt(_k_b*_temp/_K)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# initial_conditions_v = np.random.normal(mu, sigma_v, num_samples)\n",
    "initial_conditions_x = np.random.normal(mu, sigma_x, num_samples)\n",
    "\n",
    "results_speed = np.zeros((num_samples, len(times_analytic)))\n",
    "results_speed_no_half = np.zeros((num_samples, len(times_analytic)))\n",
    "results = np.zeros((num_samples, len(times_analytic)))\n",
    "\n",
    "speeds_analytic_no_half = []\n",
    "for speed in speeds:\n",
    "    print(\"Speed X\")\n",
    "    for i in range(num_samples):\n",
    "        results_speed_no_half[i, :] = full_hydro_msd(0, times_analytic, _m, _K, _r, _viscous, _rho_f, initial_conditions_x[i], speed* np.sqrt(_k_b*_temp/_m))\n",
    "    speeds_analytic_no_half.append(results_speed_no_half.mean(axis=0))\n",
    "    results_speed_no_half = np.zeros((num_samples, len(times_analytic)))\n"
   ],
   "id": "fa3f88995e999cd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed X\n",
      "Speed X\n",
      "Speed X\n",
      "Speed X\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# GRAPHING\n",
    "basset_msd = hydro_msd(times_analytic)\n",
    "# DATA GRAPHING\n",
    "plt.scatter(lag_times_data[1:], eq_msd_data[1:]/_gain**2,s=20, label=\"Equilibrium Basset DATA\", color = \"blue\")\n",
    "plt.plot(times_analytic, basset_msd, label= \"Eq Basset Analytics\")\n",
    "with open('save_out_for_figures/eq_noise.dat', 'w') as f:\n",
    "    f.write(f\"# EQ DATA \\n\")\n",
    "    data = np.column_stack((lag_times_data[1:], eq_msd_data[1:]/_gain**2))\n",
    "    np.savetxt(f, data, fmt='%.15e')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#  Set times for analytic functions\n",
    "\n",
    "init_zero_WN_analytic = just_noise(times_analytic)\n",
    "analytic_tol_msds = []\n",
    "\n",
    "WN_EQ_analytic = msd_wn(times_analytic)\n",
    "basset_msd = hydro_msd(times_analytic)\n",
    "\n",
    "# laplace_form = full_hydro_msd(0, times_analytic, _m, _K, _r, _viscous, _rho_f, np.sqrt(_k_b*_temp/_K), 0, roots, _temp)\n",
    "# laplace_form2 = full_hydro_msd(0, times_analytic, _m, _K, _r, _viscous, _rho_f, np.sqrt(_k_b*_temp/_K), (.5 * np.average(np.abs((v_traces_data[0]))))/_gain, roots, _temp)\n",
    "# stationairy1 = full_hydro_msd(1000, 1000+times_analytic, _m, _K, _r, _viscous, _rho_f, np.sqrt(_k_b*_temp/_K), np.sqrt(_k_b*_temp/_m), roots, _temp)\n",
    "# stationairy2 = full_hydro_msd(1000, 1000+times_analytic, _m, _K, _r, _viscous, _rho_f, 0,0, roots, _temp)\n",
    "\n",
    "def form_func(times):\n",
    "    return (2/3)*(12/5)*(np.sqrt((_rho_f*_r**2/_viscous)/np.pi))*(times)**(5/2)*(_k_b*_temp/(_m**2/_v_force)) - 2/3 * (_k_b*_temp/(_m**2/_v_force))*(times)**(3)\n",
    "def graph_5_2(times):\n",
    "    return (4/3)*(12/5)*(np.sqrt((_rho_f*_r**2/_viscous)/np.pi))*(times)**(5/2)*(_k_b*_temp/(_m**2/_v_force))# - 2/3 * (_k_b*_temp/(_m**2/_v_force))*(times)**(3)\n",
    "def graph_2(times):\n",
    "    return (2/100)*(np.sqrt((_rho_f*_r**2/_viscous)/np.pi))*(times)**(2)*(_k_b*_temp/(_m**2/_v_force))# - 2/3 * (_k_b*_temp/(_m**2/_v_force))*(times)**(3)\n",
    "def graph_3(times):\n",
    "    return (1000)*(np.sqrt((_rho_f*_r**2/_viscous)/np.pi))*(times)**(3)*(_k_b*_temp/(_m**2/_v_force))# - 2/3\n",
    "\n",
    "def graph_2(times):\n",
    "    return (np.sqrt((_rho_f*_r**2/_viscous)/np.pi))*(times)**(2)*(_k_b*_temp/(_m**2/_v_force))/550\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# SPEEDS\n",
    "for i in range(0, len(speeds)):\n",
    "    plt.plot(lag_times_speed_data[1:], data_speeds_msds[i][1:]/_gain**2, marker='o', markersize=1, label=f\"Data for Speed: {speeds[i]}\")\n",
    "    plt.plot(times_analytic, speeds_analytic_no_half[i], label=f\"Analytical for Speed: {speeds[i]}\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"MSD (m^2)\")\n",
    "plt.title(\"Conditioning on variable velocities\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ZERO PLOT\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(lag_times_speed_data[1:], data_speeds_msds[0][1:]/_gain**2, linestyle = 'dashed', label=f\"v(0) = 0 Data {speeds[0]}\")\n",
    "plt.plot(times_analytic, form_func(times_analytic), label= \"Short Time Derivation\")\n",
    "plt.plot(times_analytic, speeds_analytic_no_half[0], label=f\"v(0) = 0 Analytics\")\n",
    "plt.plot(times_analytic[30:int(len(times_analytic)/7)], graph_5_2(np.array(times_analytic[30:int(len(times_analytic)/7)])), label=\"5/2\", color='black', linewidth=1)\n",
    "plt.title(\"Super Balistic Hydrodynamics\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"MSD (m^2)\")\n",
    "\n",
    "with open('save_out_for_figures/noise_speeds_old.dat', 'w') as f:\n",
    "    for i in range(len(speeds)):\n",
    "        f.write(f\"# Traces used {traces_per_speed[i]} | Speed {speeds[i]}\\n\")\n",
    "        data = np.column_stack((lag_times_speed_data[1:], data_speeds_msds[i][1:] / _gain**2))\n",
    "        np.savetxt(f, data, fmt='%.15e')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "ffedd4a9b43432c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Trace length in time\n",
    "# Number of points per trace\n",
    "print(\"number of binned points per trace \"+str(len(traces_data[0])))\n",
    "print(\"length of trace (s) \" + str(len(traces_data[0])*timestep_data))\n"
   ],
   "id": "9a8070d9f129eddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b00c0bfcdd94973"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
